{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install torch torchvision\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([ transforms.ToTensor () ,\n",
    "                            transforms.Normalize ((0.5 , 0.5 , 0.5) , (0.5 , 0.5 , 0.5) ) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainset = torchvision . datasets .CIFAR10( root='./data', train=True ,\n",
    "            download=True , transform=transform ) \n",
    "testset = torchvision . datasets .CIFAR10( root='./data', train=False ,\n",
    "            download=True , transform=transform )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the CIFAR 10 dataset \n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> File Read And Processing Operations </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\"\n",
    "img_size = 32\n",
    "num_channels = 3\n",
    "img_size_flat = 3072\n",
    "num_classes = 10\n",
    "_num_files_train = 5\n",
    "# Number of images for each batch-file in the training-set.\n",
    "_images_per_file = 10000\n",
    "_num_images_train = _num_files_train * _images_per_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_file_path(filename=\"\"):\n",
    "    return os.path.join(data_path, \"cifar-10-batches-py/\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unpickle(filename):\n",
    "    file_path = _get_file_path(filename)\n",
    "    print(\"Loading data: \" + file_path)\n",
    "    with open(file_path, mode='rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_images(raw):\n",
    "    raw_float = np.array(raw,dtype=float)/255\n",
    "    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n",
    "    images = images.transpose([0,2,3,1])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoded(class_numbers, num_classes=None):\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(class_numbers) + 1\n",
    "    return np.eye(num_classes, dtype=float)[class_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(filename):\n",
    "    data = _unpickle(filename)\n",
    "    images = data[b'data']\n",
    "    cls = np.array(data[b'labels'])\n",
    "    images = _convert_images(images)\n",
    "    return images, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_names():\n",
    "    raw = _unpickle(filename=\"batches.meta\")[b'label_names']\n",
    "    names = [x.decode('utf-8') for x in raw]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data():\n",
    "    images = np.zeros(shape=[_num_images_train, img_size, img_size, num_channels], dtype=float)\n",
    "    cls = np.zeros(shape=[_num_images_train], dtype=int)\n",
    "    begin = 0\n",
    "    # For each data-file.\n",
    "    for i in range(_num_files_train):\n",
    "        # Load the images and class-numbers from the data-file.\n",
    "        images_batch, cls_batch = _load_data(filename=\"data_batch_\" + str(i + 1))\n",
    "        # Number of images in this batch.\n",
    "        num_images = len(images_batch)\n",
    "        # End-index for the current batch.\n",
    "        end = begin + num_images\n",
    "        print(end)\n",
    "        # Store the images into the array.\n",
    "        images[begin:end, :] = images_batch\n",
    "        # Store the class-numbers into the array.\n",
    "        cls[begin:end] = cls_batch\n",
    "        # The begin-index for the next batch is the current end-index.\n",
    "        begin = end\n",
    "    return images, cls, one_hot_encoded(class_numbers = cls, num_classes=num_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    images, cls = _load_data(filename=\"test_batch\")\n",
    "    return images, cls, one_hot_encoded(class_numbers = cls, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: ./data/cifar-10-batches-py/batches.meta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'airplane',\n",
       " u'automobile',\n",
       " u'bird',\n",
       " u'cat',\n",
       " u'deer',\n",
       " u'dog',\n",
       " u'frog',\n",
       " u'horse',\n",
       " u'ship',\n",
       " u'truck']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = load_class_names()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: ./data/cifar-10-batches-py/data_batch_1\n",
      "10000\n",
      "Loading data: ./data/cifar-10-batches-py/data_batch_2\n",
      "20000\n",
      "Loading data: ./data/cifar-10-batches-py/data_batch_3\n",
      "30000\n",
      "Loading data: ./data/cifar-10-batches-py/data_batch_4\n",
      "40000\n",
      "Loading data: ./data/cifar-10-batches-py/data_batch_5\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "images_train, cls_train, labels_train = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: ./data/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "images_test, cls_test, labels_test = load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to reshape the images for the purpose of inputting it to our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reshaping the images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Reshaping Dimenions..\n",
      "Training data size- Data,Labels (50000, 3072),(50000, 1)\n",
      "Test data size- Data,Labels (10000, 3072),(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "images_train = images_train.reshape(50000,-1) # -1 indicates reshaping with the leftover dimensions\n",
    "cls_train = cls_train.reshape(50000,-1)\n",
    "\n",
    "images_test = images_test.reshape(10000,-1)\n",
    "cls_test = cls_test.reshape(10000,-1)\n",
    "\n",
    "print('Post Reshaping Dimenions..')\n",
    "print('Training data size- Data,Labels {},{}'.format(images_train.shape,cls_train.shape))\n",
    "print('Test data size- Data,Labels {},{}'.format(images_test.shape,cls_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Neural Network Implementation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 10000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_images = 10000\n",
    "images_trainset = images_train[:number_of_images].T\n",
    "labels_trainset = labels_train[:number_of_images]\n",
    "images_trainset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramters for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfLayers = 3\n",
    "neurons_layer_one = 250\n",
    "neurons_layer_two = 100\n",
    "neurons_output_layer = 10;\n",
    "\n",
    "layer_dim = [images_trainset.shape[0],neurons_layer_one,neurons_layer_two,neurons_output_layer]\n",
    "parameters = {\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,dimensions):\n",
    "        self.layer_dimensions = dimensions;\n",
    "        np.random.seed(1);\n",
    "        self.parameters = parameters;\n",
    "        L = len(layer_dim)\n",
    "        \n",
    "        # initializing the weights of the Neural Network\n",
    "        for i in range(0,L-1):\n",
    "            self.parameters[\"W\"+str(i+1)] = (np.random.randn(dimensions[i+1],dimensions[i])*0.01)\n",
    "            self.parameters[\"b\"+str(i+1)] = np.zeros((dimensions[i+1],1)) \n",
    "            \n",
    "                \n",
    "    def affineForward(self,A_prev,W,b):\n",
    "        Z = np.dot(W,A_prev)+b\n",
    "        cache = (A_prev,W,b)\n",
    "        return Z,cache\n",
    "    \n",
    "    \n",
    "    def activationForward(self, A,layer_no,activation_function=\"relu\"):\n",
    "        parameters = self.parameters\n",
    "        W = parameters[\"W\"+str(layer_no)]\n",
    "        b = parameters[\"b\"+str(layer_no)]\n",
    "        Z,linear_cache = self.affineForward(A,W,b)\n",
    "        if(activation_function == \"relu\"):\n",
    "            A,activation_cache = relu(Z)\n",
    "        elif (activation_function == \"softmax\"):\n",
    "            A,activation_cache = sigmoid(Z)\n",
    "        cache = (linear_cache,activation_cache)\n",
    "        return A,cache\n",
    "        \n",
    "\n",
    "    def forwardPropagation(self,X):\n",
    "        L = len(self.layer_dimensions)\n",
    "        A = X\n",
    "        caches =[]\n",
    "        for i in range(1,L-1):\n",
    "            A_prev = A\n",
    "            A,cache = self.activationForward(A_prev,i,\"relu\")         \n",
    "            caches.append(cache)     \n",
    "        Al,cache = self.activationForward(A,L-1,\"softmax\")\n",
    "        caches.append(cache)\n",
    "        return Al,caches\n",
    "    \n",
    "    def costFunction(self,Al,y):\n",
    "        Al = Al.T\n",
    "        m = y.shape[0]\n",
    "        cost = -(1/m)*((np.sum((y*np.log(Al)))+((1-y)*(np.log(1-Al)))))\n",
    "        return cost\n",
    "    \n",
    "                                     #BackPropagation logic begin here\n",
    "    \n",
    "    def affineBackward(self,dZ,linear_cache):\n",
    "        A_prev,W,b = linear_cache\n",
    "        m = A_prev.shape[1]\n",
    "        dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "        db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "        dA_prev = np.dot(W.T,dZ)\n",
    "        return dA_prev,dW,db\n",
    "        \n",
    "    \n",
    "    def activationBackward(self, dA, cache,activation_fn):\n",
    "        linear_cache,activation_cache = cache;\n",
    "        if activation_fn == \"relu\":\n",
    "            dZ = relu_gradient(dA,activation_cache)\n",
    "            dA_prev, dW,db = self.affineBackward(dZ,linear_cache)\n",
    "        elif activation_fn == \"sigmoid\":\n",
    "            dZ = sigmoid_gradient(dA,activation_cache)\n",
    "            dA_prev, dW,db = self.affineBackward(dZ,linear_cache)\n",
    "        return dA_prev, dW,db\n",
    "    \n",
    "    \n",
    "    def backwardPropagation(self,Al,y,caches):\n",
    "        L = len(caches)\n",
    "        gradients ={}\n",
    "        dAl = np.divide(Al - y.T, np.multiply(Al, 1 - Al))\n",
    "        gradients[\"dA\"+str(L-1)],gradients[\"dW\"+str(L)],gradients[\"db\"+str(L)] = \\\n",
    "                self.activationBackward(dAl,caches[L-1],\"sigmoid\")\n",
    "        # Now backpropagation for every layer\n",
    "        for i in range(L-1,0,-1):\n",
    "            current_cache = caches[i - 1]\n",
    "            gradients[\"dA\"+str(i-1)],gradients[\"dW\"+str(i)],gradients[\"db\"+str(i)] = \\\n",
    "                    self.activationBackward(gradients[\"dA\"+str(i)],current_cache,\"relu\")\n",
    "        return gradients  \n",
    "    \n",
    "    def update_parameters(self, gradients, learning_rate):\n",
    "        parameters = self.parameters\n",
    "        L = len(parameters)\n",
    "        for l in range (1,4):\n",
    "            parameters[\"W\" + str(l)] = parameters[\n",
    "                    \"W\" + str(l)] - learning_rate * gradients[\"dW\" + str(l)]\n",
    "            parameters[\"b\" + str(l)] = parameters[\n",
    "                    \"b\" + str(l)] - learning_rate * gradients[\"db\" + str(l)]\n",
    "        return parameters\n",
    "      \n",
    "    def train(self, X,y, number_of_iterations,learning_rate,activation_fn):\n",
    "        for i in range (1,number_of_iterations):\n",
    "            Al,caches = self.forwardPropagation(X);\n",
    "            Y_pred = Al\n",
    "            cost = self.costFunction(Al,y)\n",
    "            if i % 100 == 0:\n",
    "                print (\"Cost: \", cost.mean())\n",
    "            \n",
    "            gradients = self.backwardPropagation(Al,y,caches)\n",
    "            paramters = self.update_parameters(gradients,learning_rate)\n",
    "            score = accuracy_score(cls_train[:10000],np.argmax(Y_pred.T,axis=1),normalize=True) *100;\n",
    "        return Y_pred,paramters\n",
    "    \n",
    "    def predict(self,X):\n",
    "        y_pred,caches = self.forwardPropagation(X);\n",
    "        return y_pred     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Functions\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    return A,Z\n",
    "def leaky_relu(Z):\n",
    "    A = np.maximum(0.1*Z,Z)\n",
    "    return A,Z\n",
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    return A,Z\n",
    "def tanh(Z):\n",
    "    A = (np.exp(Z)-np.exp(-Z))/(np.exp(Z)+np.exp(-Z))\n",
    "    return A,Z\n",
    "def softmax(Z):\n",
    "    Z = Z.T\n",
    "    A = (np.exp(Z))/float(sum(np.exp(Z)))\n",
    "    return A,Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(dA,Z):\n",
    "    A,Z = sigmoid(Z)\n",
    "    dZ = dA * A * (1-A)\n",
    "    return dZ\n",
    "\n",
    "def tanh_gradient(dA, Z):\n",
    "    A, Z = tanh(Z)\n",
    "    dZ = dA * (1 - np.square(A))\n",
    "\n",
    "    return dZ\n",
    "def relu_gradient(dA, Z):\n",
    "    A, Z = relu(Z)\n",
    "    dZ = np.multiply(dA, np.int64(A > 0))\n",
    "    return dZ  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((250, 3072), (100, 250), (10, 100))\n",
      "((250, 1), (100, 1), (10, 1))\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(layer_dim)\n",
    "print(model.parameters[\"W1\"].shape,model.parameters[\"W2\"].shape,model.parameters[\"W3\"].shape)\n",
    "print(model.parameters[\"b1\"].shape,model.parameters[\"b2\"].shape,model.parameters[\"b3\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 10000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_trainset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Training the model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "codeCollapsed": false,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cost: ', 0.0)\n",
      "('Cost: ', 0.0)\n",
      "('Cost: ', 0.0)\n",
      "('Cost: ', 0.0)\n",
      "('Cost: ', 0.0)\n",
      "('Cost: ', 0.0)\n",
      "('Cost: ', 0.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-a838acaab34a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparamters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_trainset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_trainset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-5b2c2ef7e99e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, number_of_iterations, learning_rate, activation_fn)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Cost: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackwardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcaches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mparamters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-5b2c2ef7e99e>\u001b[0m in \u001b[0;36mbackwardPropagation\u001b[0;34m(self, Al, y, caches)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mcurrent_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dA\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dW\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivationBackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dA\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-5b2c2ef7e99e>\u001b[0m in \u001b[0;36mactivationBackward\u001b[0;34m(self, dA, cache, activation_fn)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mactivation_fn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mdZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mdA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffineBackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinear_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mactivation_fn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mdZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-5b2c2ef7e99e>\u001b[0m in \u001b[0;36maffineBackward\u001b[0;34m(self, dZ, linear_cache)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mdA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdA_prev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Y_pred,paramters = model.train(images_trainset,labels_trainset,7000, 0.03,\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -----Training Data : 57.69%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(cls_train[:10000],np.argmax(Y_pred.T,axis=1),normalize=True) *100;\n",
    "print('Accuracy -----Training Data : {}%'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 10000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = images_test.T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Predictions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_pred = y_pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = cls_test\n",
    "Y_pred_max = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predictions.npy', Y_pred_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test Data..... : 42.699999999999996%\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_true,Y_pred_max,normalize=True)*100\n",
    "print('Accuracy for Test Data..... : {}%'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network can be made up of different number of layers and by specifying the number of neurons in those layers. Initial results showed that training the network for at least 1000 loops started giving meaningful results. Increasing the neurons increase the accuracy by a lot. After a learning rate was decided upon, the network ran for 7000 loops after which the training accuracy went up to 57% while the test accuracy was around 43%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
